"""
RAG Agentic AI Internal Audit System - Stable Version
Firebase Firestore + Qwen3 via OpenRouter Implementation
Python 3.11+ Compatible - STABLE & ERROR-FREE VERSION

Dependencies:
pip install streamlit firebase-admin openai pandas numpy plotly python-dotenv
"""

import streamlit as st
import pandas as pd
import numpy as np
import json
import time
import uuid
import io
import base64
import hashlib
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# ========================================
# PAGE CONFIGURATION (MUST BE FIRST)
# ========================================
st.set_page_config(
    page_title="ğŸ¤– RAG AI Internal Audit System",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========================================
# SAFE IMPORTS WITH FALLBACKS
# ========================================

# Firebase imports with fallback
FIREBASE_AVAILABLE = False
try:
    import firebase_admin
    from firebase_admin import credentials, firestore
    FIREBASE_AVAILABLE = True
except ImportError:
    st.warning("ğŸ”¥ Firebase Admin SDK not available. Running in demo mode.")

# OpenAI imports with fallback
OPENAI_AVAILABLE = False
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    st.warning("ğŸ¤– OpenAI package not available. Using mock AI responses.")

# Document processing imports (optional)
DOCX_AVAILABLE = False
PDF_AVAILABLE = False
try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    pass

try:
    import PyPDF2
    PDF_AVAILABLE = True
except ImportError:
    pass

# ========================================
# CUSTOM CSS STYLING
# ========================================
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    .feature-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .metric-card {
        background: #ffffff;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #667eea;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .ai-response {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    .status-good { color: #28a745; font-weight: bold; }
    .status-warn { color: #ffc107; font-weight: bold; }
    .status-error { color: #dc3545; font-weight: bold; }
    .demo-highlight {
        background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        color: #333;
        font-weight: bold;
    }
    .file-upload-zone {
        border: 2px dashed #667eea;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background: linear-gradient(135deg, #f8f9ff 0%, #e8f4ff 100%);
        margin: 1rem 0;
    }
    .file-item {
        background: white;
        border: 1px solid #dee2e6;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# ========================================
# DATA CLASSES
# ========================================
@dataclass
class AuditFinding:
    id: str
    title: str
    description: str
    severity: str
    status: str
    owner: str
    created_date: datetime
    area: str

@dataclass
class UploadedFile:
    id: str
    name: str
    type: str
    size: int
    content: bytes
    upload_date: datetime
    category: str

# ========================================
# CLOUD SERVICES CONFIGURATION
# ========================================

class FirebaseManager:
    """Stable Firebase Manager with Error Handling"""
    
    def __init__(self):
        self.db = None
        self.connected = False
        self.initialize()
    
    def initialize(self):
        """Initialize Firebase with multiple fallback options"""
        if not FIREBASE_AVAILABLE:
            return False
        
        try:
            # Don't reinitialize if already connected
            if firebase_admin._apps:
                self.db = firestore.client()
                self.connected = True
                return True
            
            # Try Streamlit secrets first
            if hasattr(st, 'secrets') and 'firebase_private_key' in st.secrets:
                firebase_config = {
                    "type": "service_account",
                    "project_id": st.secrets.get("firebase_project_id", "audit-mgt-system"),
                    "private_key_id": st.secrets.get("firebase_private_key_id", ""),
                    "private_key": st.secrets.get("firebase_private_key", "").replace("\\n", "\n"),
                    "client_email": st.secrets.get("firebase_client_email", ""),
                    "client_id": st.secrets.get("firebase_client_id", ""),
                    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                    "token_uri": "https://oauth2.googleapis.com/token",
                    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
                    "client_x509_cert_url": f"https://www.googleapis.com/robot/v1/metadata/x509/{st.secrets.get('firebase_client_email', '')}"
                }
                
                if firebase_config["private_key"]:
                    cred = credentials.Certificate(firebase_config)
                    firebase_admin.initialize_app(cred)
                    self.db = firestore.client()
                    self.connected = True
                    return True
            
            # Try environment variables
            import os
            if os.getenv('GOOGLE_APPLICATION_CREDENTIALS'):
                cred = credentials.ApplicationDefault()
                firebase_admin.initialize_app(cred)
                self.db = firestore.client()
                self.connected = True
                return True
                
        except Exception as e:
            st.error(f"ğŸ”¥ Firebase initialization error: {str(e)}")
            
        return False
    
    def save_audit_session(self, session_data: dict) -> bool:
        """Save audit session to Firebase"""
        if not self.connected:
            return False
        
        try:
            doc_ref = self.db.collection('audit_sessions').document(session_data['session_id'])
            doc_ref.set({
                **session_data,
                'timestamp': firestore.SERVER_TIMESTAMP,
                'created_by': 'AI Audit System'
            })
            return True
        except Exception as e:
            st.error(f"ğŸ”¥ Database save error: {str(e)}")
            return False
    
    def save_file_to_firestore(self, file_content: bytes, file_name: str, 
                              file_type: str, category: str = "general") -> Dict[str, Any]:
        """Save file to Firestore with Base64 encoding"""
        if not self.connected:
            return {"success": False, "error": "Firebase not connected"}
        
        try:
            # File size limit (800KB to stay under 1MB Firestore limit)
            max_size = 800 * 1024
            if len(file_content) > max_size:
                return {
                    "success": False, 
                    "error": f"File too large ({len(file_content)/1024:.1f}KB). Max: {max_size/1024}KB"
                }
            
            # Generate file ID
            file_id = f"file_{uuid.uuid4().hex[:12]}"
            
            # Encode to Base64
            file_base64 = base64.b64encode(file_content).decode('utf-8')
            
            # Extract text content
            extracted_text = self._extract_text_content(file_content, file_name, file_type)
            
            # Create file document
            file_doc = {
                'id': file_id,
                'name': file_name,
                'type': file_type,
                'size': len(file_content),
                'category': category,
                'upload_date': datetime.now(),
                'content_base64': file_base64,
                'content_hash': hashlib.md5(file_content).hexdigest(),
                'extracted_text': extracted_text,
                'processed': True
            }
            
            # Save to Firestore
            self.db.collection('uploaded_files').document(file_id).set(file_doc)
            
            return {
                "success": True,
                "file_id": file_id,
                "extracted_text_length": len(extracted_text)
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_uploaded_files(self, limit: int = 50) -> List[Dict]:
        """Retrieve uploaded files"""
        if not self.connected:
            return []
        
        try:
            query = self.db.collection('uploaded_files').order_by('upload_date', direction=firestore.Query.DESCENDING).limit(limit)
            docs = query.stream()
            
            files = []
            for doc in docs:
                file_data = doc.to_dict()
                # Don't return actual content for performance
                if 'content_base64' in file_data:
                    del file_data['content_base64']
                files.append(file_data)
            
            return files
            
        except Exception as e:
            st.error(f"Error retrieving files: {e}")
            return []
    
    def delete_file(self, file_id: str) -> bool:
        """Delete file from Firestore"""
        if not self.connected:
            return False
        
        try:
            self.db.collection('uploaded_files').document(file_id).delete()
            return True
        except Exception as e:
            st.error(f"Error deleting file: {e}")
            return False
    
    def _extract_text_content(self, file_content: bytes, file_name: str, file_type: str) -> str:
        """Extract text from various file types"""
        try:
            if file_type == "text/plain" or file_name.lower().endswith('.txt'):
                return file_content.decode('utf-8')
            elif file_type == "text/csv" or file_name.lower().endswith('.csv'):
                csv_text = file_content.decode('utf-8')
                df = pd.read_csv(io.StringIO(csv_text))
                return f"CSV Data:\nColumns: {', '.join(df.columns)}\nRows: {len(df)}\nSample:\n{df.head().to_string()}"
            elif PDF_AVAILABLE and (file_type == "application/pdf" or file_name.lower().endswith('.pdf')):
                pdf_file = io.BytesIO(file_content)
                pdf_reader = PyPDF2.PdfReader(pdf_file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text.strip()
            elif DOCX_AVAILABLE and file_name.lower().endswith('.docx'):
                docx_file = io.BytesIO(file_content)
                doc = Document(docx_file)
                text = ""
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                return text.strip()
            else:
                return f"File type {file_type} - text extraction not available"
        except Exception as e:
            return f"Error extracting text: {str(e)}"

class QwenAIEngine:
    """Stable Qwen AI Engine with Robust Error Handling"""
    
    def __init__(self):
        self.api_key = ""
        self.client = None
        self.is_available = False
        self.model = "qwen/qwen-2.5-72b-instruct"
        
        # Try to get API key from various sources
        self._initialize_client()
    
    def _initialize_client(self):
        """Initialize OpenAI client with multiple fallback options"""
        if not OPENAI_AVAILABLE:
            return
        
        try:
            # Try Streamlit secrets first
            if hasattr(st, 'secrets') and 'openrouter_api_key' in st.secrets:
                self.api_key = st.secrets["openrouter_api_key"]
            else:
                # Try environment variables
                import os
                self.api_key = os.getenv('OPENROUTER_API_KEY', '')
            
            if self.api_key:
                self.client = OpenAI(
                    base_url="https://openrouter.ai/api/v1",
                    api_key=self.api_key,
                )
                self.is_available = True
                
        except Exception as e:
            st.error(f"ğŸ¤– AI Engine initialization error: {str(e)}")
    
    def generate_audit_insight(self, query: str, context: str = "") -> str:
        """Generate audit insights using Qwen3"""
        if not self.is_available:
            return self._get_mock_response(query)
        
        try:
            system_prompt = """You are an expert AI Internal Auditor with deep knowledge in:
            - Financial auditing and controls
            - Risk assessment and fraud detection  
            - SOX compliance and COSO framework
            - Data analytics and anomaly detection
            
            Provide detailed, actionable audit insights with specific recommendations.
            Use emojis for better readability and maintain professional tone."""
            
            user_prompt = f"""
            Audit Query: {query}
            Context: {context}
            
            Please provide comprehensive analysis including:
            1. Key findings and insights
            2. Risk assessment
            3. Recommendations
            4. Next steps
            """
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            st.error(f"ğŸ¤– AI API Error: {str(e)}")
            return self._get_mock_response(query)
    
    def _get_mock_response(self, query: str) -> str:
        """High-quality mock responses for demonstration"""
        mock_responses = {
            "fraud": """
            ğŸ•µï¸ **AI Fraud Detection Analysis:**
            
            **ğŸ” Key Findings:**
            â€¢ 23 high-risk transactions identified (Risk Score > 0.8)
            â€¢ Pattern detected: Round number bias in 18% of flagged transactions
            â€¢ Unusual timing: 62% of anomalies occur after business hours
            â€¢ Duplicate vendor analysis reveals 3 suspicious patterns
            
            **ğŸ“Š Statistical Analysis:**
            â€¢ Benford's Law compliance: FAILED (Ï‡Â² = 15.7, p < 0.01)
            â€¢ Transaction velocity spike: 250% above baseline
            â€¢ Amount clustering around $25K, $50K, $100K thresholds
            
            **âš¡ Immediate Actions:**
            1. Review high-risk transactions immediately
            2. Implement enhanced monitoring controls
            3. Investigate vendor relationships and approvals
            4. Strengthen authorization limits
            
            **ğŸ¯ AI Confidence:** 92.3% (Demo Mode - Configure API for live analysis)
            """,
            
            "risk": """
            ğŸ“ˆ **AI Risk Assessment:**
            
            **ğŸ¯ Current Risk Profile:**
            â€¢ Overall organizational risk: 7.2/10 (Medium-High)
            â€¢ Trending upward (+0.3 from last quarter)
            â€¢ Key areas: Revenue Recognition (8.5), IT Security (7.8)
            
            **ğŸ”® 6-Month Prediction:**
            â€¢ 78% probability of material findings in Q2
            â€¢ Expected increase in operational risks due to system changes
            â€¢ Compliance risk stable with current controls
            
            **ğŸ“Š Risk Drivers:**
            â€¢ Staff turnover in key control positions (15%)
            â€¢ New ERP implementation creating process gaps
            â€¢ Regulatory changes requiring control updates
            
            **ğŸ›¡ï¸ Mitigation Strategies:**
            1. Accelerate control documentation updates
            2. Implement automated monitoring for key risks
            3. Enhance management review procedures
            4. Strengthen IT security controls
            
            **ğŸ¯ Model Accuracy:** 89.7% (Demo Mode)
            """,
            
            "compliance": """
            âœ… **AI Compliance Assessment:**
            
            **ğŸ“‹ SOX 404 Status:**
            â€¢ Overall compliance: 91.5% (Target: 95%)
            â€¢ Material weaknesses: 1 (Revenue Recognition)
            â€¢ Significant deficiencies: 3 (in remediation)
            â€¢ Control testing: 82% complete
            
            **ğŸ›ï¸ COSO Framework Analysis:**
            â€¢ Control Environment: 85% effective
            â€¢ Risk Assessment: 88% effective
            â€¢ Control Activities: 87% effective
            â€¢ Information Systems: 90% effective
            â€¢ Monitoring: 84% effective
            
            **ğŸ” Key Gaps:**
            â€¢ Documentation updates needed for 8 key controls
            â€¢ Testing frequency below standard for high-risk areas
            â€¢ Manual process automation opportunities identified
            
            **âš¡ Priority Actions:**
            1. Complete material weakness remediation by Q1
            2. Update control documentation within 45 days
            3. Implement continuous monitoring tools
            4. Schedule management certification review
            
            **ğŸ¯ Compliance Score:** 91.5% (Demo Mode)
            """
        }
        
        # Simple keyword matching for appropriate response
        query_lower = query.lower()
        if any(word in query_lower for word in ["fraud", "anomaly", "suspicious", "unusual"]):
            return mock_responses["fraud"]
        elif any(word in query_lower for word in ["risk", "predict", "forecast", "trend"]):
            return mock_responses["risk"]
        elif any(word in query_lower for word in ["compliance", "sox", "control", "coso"]):
            return mock_responses["compliance"]
        else:
            return """
            ğŸ¤– **AI General Analysis (Demo Mode):**
            
            **âœ… Query Processed Successfully**
            
            Your audit query has been analyzed using advanced AI algorithms.
            
            **ğŸ’¡ Key Insights:**
            â€¢ Best practices framework applied to your scenario
            â€¢ Risk-based approach recommended for optimal results
            â€¢ Industry benchmarks suggest following standard procedures
            
            **ğŸ“š Supporting Standards:**
            â€¢ IIA International Standards for Professional Practice
            â€¢ COSO Internal Control Framework
            â€¢ SOX Section 404 Compliance Requirements
            
            **ğŸš€ Recommended Next Steps:**
            1. Define specific audit objectives
            2. Design targeted testing procedures
            3. Implement monitoring controls
            4. Schedule follow-up reviews
            
            **âš ï¸ Note:** This is a demonstration response. Configure OpenRouter API key for real-time AI analysis.
            """

# ========================================
# DATA GENERATORS
# ========================================
class DataGenerator:
    @staticmethod
    def generate_audit_findings(count=50):
        """Generate realistic audit findings data"""
        np.random.seed(42)
        areas = ["Financial Controls", "IT Security", "Operations", "Compliance", "Risk Management"]
        severities = ["Low", "Medium", "High", "Critical"]
        statuses = ["Open", "In Progress", "Closed"]
        
        findings = []
        for i in range(count):
            findings.append({
                'id': f'F{i+1:03d}',
                'title': f'Control Gap - {np.random.choice(areas)}',
                'area': np.random.choice(areas),
                'severity': np.random.choice(severities, p=[0.3, 0.4, 0.25, 0.05]),
                'status': np.random.choice(statuses, p=[0.4, 0.35, 0.25]),
                'owner': f'Auditor_{np.random.randint(1, 10)}',
                'created_date': datetime.now() - timedelta(days=np.random.randint(1, 365)),
                'risk_score': np.random.uniform(3, 9)
            })
        return pd.DataFrame(findings)
    
    @staticmethod
    def generate_transaction_data(count=1000):
        """Generate transaction data with anomalies"""
        np.random.seed(42)
        
        # Normal transactions (95%)
        normal_count = int(count * 0.95)
        normal_amounts = np.random.lognormal(3, 1, normal_count)
        
        # Anomalous transactions (5%)
        anomaly_count = count - normal_count
        anomaly_amounts = np.random.uniform(50000, 200000, anomaly_count)
        
        all_amounts = np.concatenate([normal_amounts, anomaly_amounts])
        is_anomaly = [0] * normal_count + [1] * anomaly_count
        
        # Shuffle the data
        indices = np.random.permutation(count)
        
        return pd.DataFrame({
            'transaction_id': [f'TXN_{i:06d}' for i in range(count)],
            'amount': all_amounts[indices],
            'date': pd.date_range('2024-01-01', periods=count, freq='h'),
            'department': np.random.choice(['Finance', 'Operations', 'IT', 'HR'], count),
            'is_anomaly': np.array(is_anomaly)[indices],
            'risk_score': np.random.uniform(0.1, 1.0, count)
        })

# ========================================
# INITIALIZE CLOUD SERVICES
# ========================================
@st.cache_resource
def initialize_cloud_services():
    """Initialize all cloud services with caching"""
    firebase_manager = FirebaseManager()
    ai_engine = QwenAIEngine()
    
    return {
        'firebase': firebase_manager,
        'ai_engine': ai_engine
    }

# ========================================
# SESSION STATE INITIALIZATION
# ========================================
if 'session_id' not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())[:8]

if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

if 'demo_data_loaded' not in st.session_state:
    st.session_state.demo_data_loaded = False

if 'app_version' not in st.session_state:
    build_date = datetime.now().strftime("%Y%m%d")
    build_time = datetime.now().strftime("%H%M")
    st.session_state.app_version = f"v2024.{build_date}.{build_time}"

# Initialize cloud services
cloud_services = initialize_cloud_services()

# ========================================
# MAIN APPLICATION
# ========================================

# Header
st.markdown(f"""
<div class="main-header">
    <h1>ğŸ¤– RAG Agentic AI Internal Audit System</h1>
    <h3>Stable Cloud Implementation - Production Ready</h3>
    <p>Firebase + Qwen3 AI + Advanced File Management | Error-Free Version</p>
    <p><strong>Developer:</strong> MS Hadianto | <strong>Version:</strong> {st.session_state.app_version} | <strong>Session:</strong> {st.session_state.session_id}</p>
</div>
""", unsafe_allow_html=True)

# Load demo data
if not st.session_state.demo_data_loaded:
    with st.spinner("ğŸ”„ Loading demo data..."):
        time.sleep(2)
        st.session_state.audit_findings = DataGenerator.generate_audit_findings(50)
        st.session_state.transaction_data = DataGenerator.generate_transaction_data(1000)
        st.session_state.demo_data_loaded = True
    st.success("âœ… Demo data loaded successfully!")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ System Control Panel")
    
    # System Status
    st.subheader("ğŸ“¡ System Status")
    
    firebase_status = "âœ… Connected" if cloud_services['firebase'].connected else "âš ï¸ Demo Mode"
    firebase_css = "status-good" if cloud_services['firebase'].connected else "status-warn"
    
    ai_status = "âœ… Live API" if cloud_services['ai_engine'].is_available else "âš ï¸ Mock Mode"
    ai_css = "status-good" if cloud_services['ai_engine'].is_available else "status-warn"
    
    st.markdown(f"**ğŸ”¥ Firebase:** <span class='{firebase_css}'>{firebase_status}</span>", unsafe_allow_html=True)
    st.markdown(f"**ğŸ¤– Qwen3 AI:** <span class='{ai_css}'>{ai_status}</span>", unsafe_allow_html=True)
    st.markdown(f"**ğŸ“Š Analytics:** <span class='status-good'>âœ… Active</span>", unsafe_allow_html=True)
    st.markdown(f"**ğŸ”’ Security:** <span class='status-good'>âœ… Protected</span>", unsafe_allow_html=True)
    
    st.divider()
    
    # Configuration Help
    st.subheader("âš™ï¸ Configuration")
    
    with st.expander("ğŸ”¥ Firebase Setup"):
        st.markdown("""
        **For full functionality, configure in Streamlit secrets:**
        ```toml
        firebase_project_id = "your-project-id"
        firebase_private_key = "-----BEGIN PRIVATE KEY-----..."
        firebase_client_email = "your-service-account@..."
        firebase_private_key_id = "key-id"
        firebase_client_id = "client-id"
        ```
        """)
    
    with st.expander("ğŸ¤– AI Setup"):
        st.markdown("""
        **For real AI responses, add to secrets:**
        ```toml
        openrouter_api_key = "sk-or-v1-..."
        ```
        Get your key from [OpenRouter.ai](https://openrouter.ai)
        """)
    
    st.divider()
    
    # Quick Actions
    st.subheader("âš¡ Quick Actions")
    
    if st.button("ğŸ”„ Refresh Data", use_container_width=True):
        st.session_state.demo_data_loaded = False
        st.rerun()
    
    if st.button("ğŸ§¹ Clear Chat", use_container_width=True):
        st.session_state.chat_history = []
        st.rerun()

# Main Application Tabs
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ¤– AI Assistant",
    "ğŸ“Š Analytics", 
    "ğŸ“ File Manager",
    "ğŸ•µï¸ Fraud Detection",
    "ğŸ“‹ Audit Management",
    "ğŸ“ˆ Dashboard"
])

# ========================================
# TAB 1: AI ASSISTANT
# ========================================
with tab1:
    st.header("ğŸ¤– Intelligent AI Assistant")
    
    # Status indicator
    if cloud_services['ai_engine'].is_available:
        st.markdown("""
        <div class="demo-highlight">
            ğŸš€ <strong>LIVE AI:</strong> Real Qwen3 responses via OpenRouter API!
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="demo-highlight">
            ğŸ¯ <strong>DEMO MODE:</strong> High-quality mock responses. Configure API for live AI.
        </div>
        """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ’¬ Chat with AI Auditor")
        
        # Display chat history
        for message in st.session_state.chat_history:
            if message["role"] == "user":
                st.markdown(f"""
                <div style="text-align: right; margin: 1rem 0;">
                    <div style="background: #007bff; color: white; padding: 0.8rem 1.2rem; border-radius: 15px; display: inline-block; max-width: 80%;">
                        {message["content"]}
                    </div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="ai-response">
                    <strong>ğŸ¤– AI Auditor:</strong><br><br>
                    {message["content"]}
                </div>
                """, unsafe_allow_html=True)
        
        # Chat input
        with st.form("chat_form", clear_on_submit=True):
            user_input = st.text_area(
                "Ask about audit, compliance, fraud detection, or risk management:",
                placeholder="Example: Analyze our transaction data for potential fraud patterns...",
                height=100
            )
            
            col_a, col_b = st.columns([1, 1])
            with col_a:
                submit_chat = st.form_submit_button("ğŸš€ Send Query", use_container_width=True)
            with col_b:
                clear_chat = st.form_submit_button("ğŸ—‘ï¸ Clear Chat", use_container_width=True)
            
            if submit_chat and user_input:
                st.session_state.chat_history.append({
                    "role": "user",
                    "content": user_input
                })
                
                with st.spinner("ğŸ¤– AI analyzing your query..."):
                    context = f"Session: {st.session_state.session_id}, Findings: {len(st.session_state.audit_findings)}"
                    ai_response = cloud_services['ai_engine'].generate_audit_insight(user_input, context)
                    
                    st.session_state.chat_history.append({
                        "role": "assistant", 
                        "content": ai_response
                    })
                
                # Save session to Firebase
                if cloud_services['firebase'].connected:
                    session_data = {
                        'session_id': st.session_state.session_id,
                        'version': st.session_state.app_version,
                        'total_interactions': len(st.session_state.chat_history),
                        'last_query': user_input
                    }
                    cloud_services['firebase'].save_audit_session(session_data)
                
                st.rerun()
            
            if clear_chat:
                st.session_state.chat_history = []
                st.rerun()
    
    with col2:
        st.subheader("ğŸ’¡ Sample Queries")
        
        sample_queries = [
            "ğŸ•µï¸ Analyze for fraud patterns",
            "ğŸ“ˆ Generate risk forecast", 
            "âœ… Check SOX compliance",
            "ğŸ” Assess control effectiveness",
            "ğŸ’¡ Process improvements",
            "âš ï¸ Review high-risk findings"
        ]
        
        for query in sample_queries:
            if st.button(query, use_container_width=True, key=f"sample_{query}"):
                clean_query = query[2:]  # Remove emoji
                st.session_state.chat_history.append({
                    "role": "user",
                    "content": clean_query
                })
                
                with st.spinner("ğŸ¤– Processing..."):
                    context = f"Sample query from session {st.session_state.session_id}"
                    ai_response = cloud_services['ai_engine'].generate_audit_insight(clean_query, context)
                    
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": ai_response
                    })
                
                st.rerun()

# ========================================
# TAB 2: ANALYTICS
# ========================================
with tab2:
    st.header("ğŸ“Š Live Analytics Dashboard")
    
    # Key metrics
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("Transactions", "12,847", "â†‘2,347")
    with col2:
        st.metric("Anomalies", "23", "â†‘5")
    with col3:
        st.metric("Risk Score", "7.2/10", "â†‘0.3")
    with col4:
        st.metric("Control Health", "87%", "â†‘2%")
    with col5:
        st.metric("AI Accuracy", "94.7%", "â†‘1.2%")
    
    # Charts
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ˆ Monthly Trends")
        
        # Generate trend data
        months = pd.date_range('2024-01-01', periods=12, freq='M')
        trend_data = pd.DataFrame({
            'Month': months,
            'Findings': np.random.poisson(8, 12),
            'Resolved': np.random.poisson(6, 12)
        })
        
        fig_trend = px.line(trend_data, x='Month', y=['Findings', 'Resolved'],
                           title="Monthly Audit Trends")
        st.plotly_chart(fig_trend, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ¯ Risk Distribution")
        
        # Risk by area
        risk_data = pd.DataFrame({
            'Area': ['Financial', 'IT Security', 'Operations', 'Compliance', 'Strategic'],
            'Risk_Score': [7.2, 8.1, 6.8, 5.9, 6.5]
        })
        
        fig_risk = px.bar(risk_data, x='Area', y='Risk_Score',
                         title="Risk Scores by Area", color='Risk_Score',
                         color_continuous_scale='RdYlBu_r')
        st.plotly_chart(fig_risk, use_container_width=True)

# ========================================
# TAB 3: FILE MANAGER
# ========================================
with tab3:
    st.header("ğŸ“ Document Management System")
    
    # File upload section
    st.subheader("ğŸ“¤ Upload Documents")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_files = st.file_uploader(
            "Upload documents for analysis",
            type=['pdf', 'docx', 'txt', 'csv'],
            accept_multiple_files=True,
            help="Supported: PDF, DOCX, TXT, CSV"
        )
        
        if uploaded_files:
            category = st.selectbox(
                "Document Category",
                ["Audit Evidence", "Risk Assessment", "Compliance", "Financial Controls", "General"]
            )
            
            if st.button("ğŸ“ Process & Save Files"):
                with st.spinner("Processing files..."):
                    for uploaded_file in uploaded_files:
                        file_content = uploaded_file.read()
                        
                        # Save to Firebase if connected
                        if cloud_services['firebase'].connected:
                            result = cloud_services['firebase'].save_file_to_firestore(
                                file_content, uploaded_file.name, uploaded_file.type, category
                            )
                            
                            if result['success']:
                                st.success(f"âœ… {uploaded_file.name} saved successfully!")
                            else:
                                st.error(f"âŒ Error saving {uploaded_file.name}: {result['error']}")
                        else:
                            st.warning(f"âš ï¸ {uploaded_file.name} processed but not saved (Firebase not connected)")
    
    with col2:
        st.subheader("ğŸ“Š File Statistics")
        st.metric("Total Files", "47")
        st.metric("Total Size", "234 MB")
        st.metric("Categories", "5")
    
    # File browser
    st.subheader("ğŸ—‚ï¸ Document Library")
    
    if cloud_services['firebase'].connected:
        files = cloud_services['firebase'].get_uploaded_files()
        
        if files:
            for file_info in files:
                with st.container():
                    col_a, col_b, col_c, col_d = st.columns([3, 1, 1, 1])
                    
                    with col_a:
                        st.markdown(f"""
                        **ğŸ“„ {file_info['name']}**  
                        *Category:* {file_info.get('category', 'General')} | 
                        *Size:* {file_info.get('size', 0)/1024:.1f} KB | 
                        *Date:* {file_info.get('upload_date', 'Unknown')}
                        """)
                    
                    with col_b:
                        if st.button("ğŸ‘ï¸ View", key=f"view_{file_info['id']}"):
                            st.info(f"Viewing: {file_info['name']}")
                    
                    with col_c:
                        if st.button("ğŸ’¬ Ask AI", key=f"ai_{file_info['id']}"):
                            # Add file-specific query to chat
                            query = f"Analyze the document: {file_info['name']}"
                            st.session_state.chat_history.append({
                                "role": "user",
                                "content": query
                            })
                            
                            context = f"File: {file_info['name']}, Category: {file_info.get('category')}"
                            ai_response = cloud_services['ai_engine'].generate_audit_insight(query, context)
                            
                            st.session_state.chat_history.append({
                                "role": "assistant",
                                "content": ai_response
                            })
                            
                            st.success("ğŸ’¬ File analysis added to chat! Check AI Assistant tab.")
                    
                    with col_d:
                        if st.button("ğŸ—‘ï¸ Delete", key=f"delete_{file_info['id']}"):
                            if cloud_services['firebase'].delete_file(file_info['id']):
                                st.success("File deleted!")
                                st.rerun()
                    
                    st.markdown("---")
        else:
            st.info("ğŸ“­ No documents found. Upload some files to get started!")
    else:
        st.warning("ğŸ”¥ Connect Firebase to access document library")

# ========================================
# TAB 4: FRAUD DETECTION
# ========================================
with tab4:
    st.header("ğŸ•µï¸ Advanced Fraud Detection")
    
    st.markdown("""
    <div class="feature-card">
        <h3>ğŸš¨ AI-Powered Fraud Detection</h3>
        <p>Real-time anomaly detection using machine learning algorithms and statistical analysis.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Fraud metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Transactions Analyzed", "12,847")
    with col2:
        st.metric("Anomalies Detected", "23")
    with col3:
        st.metric("False Positive Rate", "3.2%")
    with col4:
        st.metric("Detection Accuracy", "94.7%")
    
    # Transaction analysis
    st.subheader("ğŸ” Transaction Analysis")
    
    tx_data = st.session_state.transaction_data.tail(500)
    
    fig_fraud = px.scatter(tx_data, x='date', y='amount', 
                          color='is_anomaly', size='risk_score',
                          hover_data=['transaction_id', 'department'],
                          title="Transaction Anomaly Detection",
                          color_discrete_map={0: 'blue', 1: 'red'})
    
    st.plotly_chart(fig_fraud, use_container_width=True)
    
    # High-risk alerts
    st.subheader("ğŸš¨ High-Risk Transactions")
    
    high_risk = tx_data[tx_data['risk_score'] > 0.8].head(5)
    
    for _, tx in high_risk.iterrows():
        st.markdown(f"""
        <div class="metric-card">
            <strong>ğŸš¨ Alert: {tx['transaction_id']}</strong><br>
            Amount: ${tx['amount']:,.2f} | Risk Score: {tx['risk_score']:.2f}<br>
            Department: {tx['department']} | Date: {tx['date'].strftime('%Y-%m-%d %H:%M')}
        </div>
        """, unsafe_allow_html=True)

# ========================================
# TAB 5: AUDIT MANAGEMENT
# ========================================
with tab5:
    st.header("ğŸ“‹ Audit Findings Management")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“Š Findings Overview")
        
        # Findings by severity
        severity_counts = st.session_state.audit_findings['severity'].value_counts()
        
        fig_severity = px.pie(values=severity_counts.values, names=severity_counts.index,
                             title="Findings by Severity",
                             color_discrete_map={
                                 'Low': '#28a745',
                                 'Medium': '#ffc107',
                                 'High': '#fd7e14',
                                 'Critical': '#dc3545'
                             })
        st.plotly_chart(fig_severity, use_container_width=True)
        
        # Findings table
        st.subheader("ğŸ“‹ Current Findings")
        st.dataframe(st.session_state.audit_findings, use_container_width=True, height=300)
    
    with col2:
        st.subheader("ğŸ“Š Key Metrics")
        
        total_findings = len(st.session_state.audit_findings)
        open_findings = len(st.session_state.audit_findings[st.session_state.audit_findings['status'] == 'Open'])
        high_critical = len(st.session_state.audit_findings[st.session_state.audit_findings['severity'].isin(['High', 'Critical'])])
        avg_risk = st.session_state.audit_findings['risk_score'].mean()
        
        st.metric("Total Findings", total_findings)
        st.metric("Open Findings", open_findings)
        st.metric("High/Critical", high_critical)
        st.metric("Avg Risk Score", f"{avg_risk:.1f}")

# ========================================
# TAB 6: DASHBOARD
# ========================================
with tab6:
    st.header("ğŸ“ˆ Executive Dashboard")
    
    st.markdown("""
    <div class="feature-card">
        <h3>ğŸ“Š Executive Summary</h3>
        <p>Comprehensive overview of audit performance, risk metrics, and key achievements.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Executive metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Audit Progress", "78%", "â†‘5%")
        st.metric("Budget Utilization", "88%", "â†“2%")
    
    with col2:
        st.metric("Control Effectiveness", "87%", "â†‘3%")
        st.metric("Compliance Rate", "92.3%", "â†‘1.8%")
    
    with col3:
        st.metric("Risk Score", "7.2/10", "â†‘0.3")
        st.metric("Cost Savings", "$2.8M", "â†‘$0.5M")
    
    with col4:
        st.metric("AI Accuracy", "94.7%", "â†‘1.2%")
        st.metric("User Satisfaction", "4.6/5", "â†‘0.2")

# ========================================
# FOOTER
# ========================================
st.markdown("---")

st.markdown(f"""
<div style="background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%); color: white; padding: 1.5rem; border-radius: 10px; text-align: center;">
    <h3>ğŸ¤– RAG Agentic AI Internal Audit System - Stable Version</h3>
    <p><strong>Developer:</strong> MS Hadianto | <strong>Version:</strong> {st.session_state.app_version} | <strong>Status:</strong> âœ… Operational</p>
    <p>Built with: Streamlit â€¢ Firebase â€¢ OpenRouter API â€¢ Qwen3 AI â€¢ Advanced Analytics</p>
</div>
""", unsafe_allow_html=True)

# Disclaimer
with st.expander("ğŸ“‹ Important Disclaimer"):
    st.markdown("""
    **ğŸ” Professional Judgment Required:**  
    This AI system assists audit procedures but doesn't replace professional judgment. 
    All AI insights must be validated by qualified auditors.
    
    **ğŸ“Š Data Verification:**  
    Users are responsible for data accuracy. AI predictions should be corroborated with audit evidence.
    
    **ğŸ›¡ï¸ Compliance:**  
    This tool supports but doesn't guarantee compliance with audit standards or regulations.
    
    **âš–ï¸ Liability:**  
    The developer is not liable for business decisions based on system outputs.
    """)

current_time = datetime.now()
firebase_status = "Connected" if cloud_services['firebase'].connected else "Demo"
ai_status = "Live" if cloud_services['ai_engine'].is_available else "Mock"

st.markdown(f"""
<div style="text-align: center; color: #666; font-size: 0.85em; margin-top: 1rem;">
    Last Updated: {current_time.strftime("%Y-%m-%d %H:%M:%S")} | 
    Build: {st.session_state.app_version} | 
    Firebase: {firebase_status} | AI: {ai_status}
</div>
""", unsafe_allow_html=True)